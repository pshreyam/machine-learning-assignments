{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c00ca55-c072-44af-97e2-ad8d07be9629",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network\n",
    "\n",
    "## (Book: Mastering Machine Learning with Python in Six Steps)\n",
    "\n",
    "Ideal modeling choice to work in sequential data for speech text mining image captioning, time series prediction, robot control,\n",
    "language modeling, etc.\n",
    "\n",
    "Feedback from previous step is provided to the current step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bae71c9-861c-4df7-ad26-a3d20f21071c",
   "metadata": {},
   "source": [
    "## Long Short Term Memory(LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f650920a-5e0a-4d42-85d2-9682846bbc17",
   "metadata": {},
   "source": [
    "LSTM is an implementation of improved RNN architecture to address the issues of \n",
    "general RNN, and it enables long-range dependencies. It is designed to have better \n",
    "memory through linear memory cells surrounded by a set of gate units used to control \n",
    "the flow of informationâ€”when information should enter the memory, when to forget, \n",
    "and when to output. It uses no activation function within its recurrent components, thus \n",
    "the gradient term does not vanish with backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9ebaebc-cf9e-4a96-95a9-7e3fff199ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 19:37:20.368330: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-22 19:37:20.368390: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2017)\n",
    "\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6b5bf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "X_train shape: (25000, 80)\n",
      "X_test shape: (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000\n",
    "maxlen = 80 # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "print('Loading data...')\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a29cdd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 19:37:58.496045: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-22 19:37:58.496086: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-22 19:37:58.496111: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (arch): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "# Defining the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, recurrent_dropout=0.2, dropout=0.2))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a852a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92c95872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 247s 310ms/step - loss: 0.4288 - accuracy: 0.8036 - val_loss: 0.3593 - val_accuracy: 0.8448\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 229s 293ms/step - loss: 0.2578 - accuracy: 0.8965 - val_loss: 0.3741 - val_accuracy: 0.8364\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 227s 290ms/step - loss: 0.1674 - accuracy: 0.9364 - val_loss: 0.4073 - val_accuracy: 0.8274\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 227s 290ms/step - loss: 0.1115 - accuracy: 0.9594 - val_loss: 0.5196 - val_accuracy: 0.8154\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 245s 313ms/step - loss: 0.0818 - accuracy: 0.9698 - val_loss: 0.6250 - val_accuracy: 0.8194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ffabdbfc7f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=5, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b840b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 40s 51ms/step - loss: 0.0371 - accuracy: 0.9908\n",
      "782/782 [==============================] - 39s 49ms/step - loss: 0.6250 - accuracy: 0.8194\n"
     ]
    }
   ],
   "source": [
    "train_score, train_acc = model.evaluate(X_train, y_train, batch_size=batch_size)\n",
    "test_score, test_acc = model.evaluate(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbc29f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.0371478870511055\n",
      "Train accuracy: 0.9907600283622742\n",
      "Test score: 0.6249503493309021\n",
      "Test accuracy: 0.8193600177764893\n"
     ]
    }
   ],
   "source": [
    "print('Train score:', train_score)\n",
    "print('Train accuracy:', train_acc)\n",
    "print ('Test score:', test_score)\n",
    "print ('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7cd672",
   "metadata": {},
   "source": [
    "## Transfer Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660185b9",
   "metadata": {},
   "source": [
    "Based on our past experience, we humans can learn a new skill easily. We are more\n",
    "efficient in learning, particularly if the task at hand is similar to what we have done in the\n",
    "past. For example, learning a new programming language for a computer professional\n",
    "or driving a new type of vehicle for a seasoned driver is relatively easy, based on our past\n",
    "experience.\n",
    "\n",
    "Transfer learning is an area in ML that aims to utilize the knowledge gained while\n",
    "solving one problem to solve a different but related problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18e246c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2017)\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04d095f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "nb_classes = 5\n",
    "nb_epoch = 5\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "pool_size = 2\n",
    "# convolution kernel size\n",
    "kernel_size = 3\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "972e5b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 132s 11us/step\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa9e2efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two datasets one with digits below 5 and one with 5 and above\n",
    "X_train_lt5 = X_train[y_train < 5]\n",
    "y_train_lt5 = y_train[y_train < 5]\n",
    "\n",
    "X_test_lt5 = X_test[y_test < 5]\n",
    "y_test_lt5 = y_test[y_test < 5]\n",
    "X_train_gte5 = X_train[y_train >= 5]\n",
    "y_train_gte5 = y_train[y_train >= 5] - 5 # make classes start at 0 for\n",
    "X_test_gte5 = X_test[y_test >= 5] # np_utils.to_categorical\n",
    "y_test_gte5 = y_test[y_test >= 5] - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fc1d268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model for digits 0 to 4\n",
    "def train_model(model, train, test, nb_classes):\n",
    "    X_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
    "    X_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print(X_train.shape[0], 'train samples')\n",
    "    print(X_test.shape[0], 'test samples')\n",
    "    \n",
    "    # convert class vectors to binary class matrices\n",
    "    Y_train = np_utils.to_categorical(train[1], nb_classes)\n",
    "    Y_test = np_utils.to_categorical(test[1], nb_classes)\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adadelta',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        batch_size=batch_size, \n",
    "        epochs=nb_epoch,\n",
    "        verbose=1,\n",
    "        validation_data=(X_test, Y_test)\n",
    "    )\n",
    "    score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5fd100b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two groups of layers: feature (convolutions) and classification(dense)\n",
    "\n",
    "feature_layers = [\n",
    "    Conv2D(nb_filters, kernel_size,\n",
    "    padding=\"valid\",\n",
    "    input_shape=input_shape),\n",
    "    Activation(\"relu\"),\n",
    "    Conv2D(nb_filters, kernel_size),\n",
    "    Activation(\"relu\"),\n",
    "    MaxPooling2D(pool_size=(pool_size, pool_size)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "]\n",
    "\n",
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation(\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(nb_classes),\n",
    "    Activation(\"softmax\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49862ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create complete model\n",
    "model = Sequential(feature_layers + classification_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "386a4729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (30596, 28, 28, 1)\n",
      "30596 train samples\n",
      "5139 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 20:39:13.252182: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 95949056 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "240/240 [==============================] - 89s 321ms/step - loss: 1.5843 - accuracy: 0.2616 - val_loss: 1.5420 - val_accuracy: 0.4660\n",
      "Epoch 2/5\n",
      "240/240 [==============================] - 60s 248ms/step - loss: 1.5297 - accuracy: 0.3610 - val_loss: 1.4793 - val_accuracy: 0.6196\n",
      "Epoch 3/5\n",
      "240/240 [==============================] - 56s 235ms/step - loss: 1.4691 - accuracy: 0.4606 - val_loss: 1.4117 - val_accuracy: 0.7178\n",
      "Epoch 4/5\n",
      "240/240 [==============================] - 56s 233ms/step - loss: 1.4043 - accuracy: 0.5411 - val_loss: 1.3350 - val_accuracy: 0.8109\n",
      "Epoch 5/5\n",
      "240/240 [==============================] - 57s 237ms/step - loss: 1.3321 - accuracy: 0.6142 - val_loss: 1.2482 - val_accuracy: 0.8607\n",
      "Test score: 1.2482320070266724\n",
      "Test accuracy: 0.8606733083724976\n"
     ]
    }
   ],
   "source": [
    "# train model for 5-digit classification [0..4]\n",
    "train_model(model, (X_train_lt5, y_train_lt5), (X_test_lt5, y_test_lt5),\n",
    "nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146b402d",
   "metadata": {},
   "source": [
    "Transfer existing trained model on 0 to 4 to build model for digits 5 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1a00bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze feature layers and rebuild model\n",
    "for layer in feature_layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1342bece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (29404, 28, 28, 1)\n",
      "29404 train samples\n",
      "4861 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 20:49:46.013697: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 92210944 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "230/230 [==============================] - 20s 80ms/step - loss: 1.5997 - accuracy: 0.2932 - val_loss: 1.5438 - val_accuracy: 0.4026\n",
      "Epoch 2/5\n",
      "230/230 [==============================] - 21s 90ms/step - loss: 1.5411 - accuracy: 0.3399 - val_loss: 1.4837 - val_accuracy: 0.4701\n",
      "Epoch 3/5\n",
      "230/230 [==============================] - 22s 94ms/step - loss: 1.4851 - accuracy: 0.3987 - val_loss: 1.4271 - val_accuracy: 0.5489\n",
      "Epoch 4/5\n",
      "230/230 [==============================] - 20s 89ms/step - loss: 1.4349 - accuracy: 0.4573 - val_loss: 1.3736 - val_accuracy: 0.6274\n",
      "Epoch 5/5\n",
      "230/230 [==============================] - 19s 80ms/step - loss: 1.3868 - accuracy: 0.5145 - val_loss: 1.3224 - val_accuracy: 0.6885\n",
      "Test score: 1.322437047958374\n",
      "Test accuracy: 0.6885414719581604\n"
     ]
    }
   ],
   "source": [
    "# transfer: train dense layers for new classification task [5..9]\n",
    "train_model(\n",
    "    model, \n",
    "    (X_train_gte5, y_train_gte5),\n",
    "    (X_test_gte5, y_test_gte5), \n",
    "    nb_classes\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
